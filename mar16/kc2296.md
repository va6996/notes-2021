---
title: "Storage: Privacy and Policies"
author: Kevin Choi <kc2296@nyu.edu>
---
# Introduction
Explosion of data (a la "data is the new oil"), commoditization of data, manipulation of data, data breaches, and resulting violations of privacy have been a huge issue in the past years, prompting legislations such as GDPR (General Data Protection Regulation) and CCPA (California Consumer Privacy Act). Given recent developments (both legal and technological), what are some ways through which we can address data privacy issues?

This week's papers delineate the following three angles:
1. Hiding access patterns (from untrusted cloud providers) using ORAM while providing ACID transactions -- Obladi (Crooks et al.)
2. Providing statistics on aggregate data without leaking individual data points -- differential privacy (Dwork et al.)
3. Making database systems compliant to GDPR at an implementation level and providing a benchmark for future systems -- GDPRbench (Shastri et al.)

# Motivation
## Obladi
The general problem of trusting a cloud provider is a substantial one. Consider an online bookstore or an online streaming service hosted on AWS, meaning all data collected by those services are processed by Amazon in the backend. What if Amazon offers similar services and maliciously extracts relevant information from the competitors to Amazon's benefit?

While cryptographic encryptions can aid in hiding the data points per se, there have been revelations that mere access patterns (i.e. how frequently something has been accessed) can in fact reveal sensitive information in an undesirable manner. For instance, it is possible that access patterns in the context of cancer treatment of patients can reveal the type and severity of a patient's cancer (even with encryption and/or anonymization). While prior uses of ORAM to hide access patterns have existed already, Obladi's novelty is that it is the first system to provide ACID transactions while hiding access patterns.

## Differential Privacy
There are instances where we would like to know something about the aggregate data (e.g. mean, median, etc.) but not the individual data points for privacy reasons. The US Census is a good example. An attempt to achieve this has motivated differential privacy.

## GDPRbench
While GDPR specifies various legal requirements, rights of the people, responsibilities of the data controllers and processors, etc., a practical analysis of these specifications at the implementation level has not been conducted before. From a database systems perspective, how can one realize GDPR in preexisting systems? How would realizing it affect performance? Can there be a GDPR-compliant benchmark for future systems? These are the questions that the GDPRbench paper seeks to offer insight on.

# Approaches and Trade-Offs
## Obladi
A strawman solution to supporting ACID transactions while hiding access patterns would be to simply replace the existing database storage with an arbitrary ORAM. The issue with this is two-fold. In terms of security, there could be information leakage during concurrency control (e.g. write operations blocking the progress of read operations) and failure recovery (e.g. undo logging). In terms of performance, ORAM's intended goal aligns poorly with modern performance goals.

Addressing above, Obladi's approaches are the following:
* Obladi uses multiversioned concurrency control (MVTSO, short for multiversioned timestamp ordering) so that read operations can proceed without blocking whereas intermediate writes are buffered locally.
* Epoch-based (subdivided into read phase and write phase, in which batching becomes prevalent) approach helps with performance (i.e. via delayed committing of transactions until the end of an epoch and parallelism) and failure recovery.
* As for the ORAM implementation itself, Obladi leverages Ring ORAM, which guarantees a constant stash size and a fully deterministic eviction phase.
* Obladi's security proof is presented under the UC (Universal Composability) framework a la MPC and ideal functionality.

While Obladi's throughput comes within 5x to 12x of a non-oblivious baseline on the TPC-C, SmallBank, and FreeHealth applications, latency overheads are higher, e.g. 70x on TPC-C.

## Differential Privacy
1. Laplace mechanism: The basic idea (in the original global model) is that random noise is drawn from a predefined probability distribution (e.g. Laplace) and summed with the true query in order to hide the query. In the local model, random noise is added to each data point, and a query is made to those modified data points. Generally, the amount of noise is dependent on the so-called privacy budget Îµ and sensitivity of the query.
2. Exponential mechanism: When adding a noise doesn't make sense (e.g. to categorical data), one can define a utility function and in a way "assign" probabilities to each output in the output space.

Note that the more fundamental idea behind the above approaches is the concept of plausible deniability. Due to the noise added, one (corresponding to one data point in a dataset) can plausibly deny his data point when accused such that we are able to gain information on some aggregate data without having the ability to pinpoint where exactly that information should originate from. This protects the privacy of those involved in a dataset. A typical tradeoff is one called the privacy-utility tradeoff: too much privacy would yield dubious utility whereas maximizing utility may harm privacy. In a similar vein, one has to be cautious regarding the privacy budget, as re-querying the same dataset multiple times may exhaust the privacy budget and hence harm privacy.

## GDPRbench
Some challenges to keep in mind when realizing GDPR include the following:
* GDPR's interpretation of personal data is quite broad such that it includes any information (e.g. search term on Google) that relates to a person.
* Vagueness exists perhaps in order to accommodate future advancements in technology. For instance, GDPR does not specify how shortly after a Right To Be Forgotten request should the data be erased. Google does this within 180 days of request, but a strict, worst-case interpretation of the requirement could be necessary for analysis purposes.

The GDPRbench paper not only modifies the preexisting database systems to be GDPR-compliant in order to perform analysis on the impact of GDPR on database systems, but also provides a benchmark for future systems.

Modifying the preexisting and analyzing them
* Three widely used database systems are considered: Redis, Postgres, and System-C (pseudonym for some enterprise-grade RDBMS). The reason is to consider systems from different parts of the spectrum, e.g. SQL vs NoSQL, fully featured vs minimalist, open-source vs commercial, etc.
* GDPR's required security features can be grouped into 5 buckets: TTL (time to live), encryption, auditing, metadata indexing, and access control.
* Redis needs 120 lines of code changes. Postgres needs 30 lines of scripting. System-C needs mostly configuration changes.
* It is analyzed that GDPR compliance incurs performance degradation of 2x to 5x. As Redis corresponds to 5x in performance degradation, it is observed that compliance is more effective with RDBMS than NoSQL stores.
* GDPR compliance incurs a linear relationship between query completion time and DB size such that scaling becomes an issue.

GDPRbench (benchmark)
* GDPR specifies 4 entities (controller, customer, processor, and regulator) and distinguishes between 3 types of data (personal data, GDPR metadata, and derived data).
* Accordingly, the following metadata attributes must be stored for all data: purpose, TTL, objections, audit trail, origin and sharing, automated decision-making, and associated person. The following features are required: timely deletion, monitoring and logging, metadata indexing, encryption, and access control. It is with these in mind that one can devise GDPR queries.
* As per GDPR, GDPRbench defines four workloads, each corresponding to one of controller, customer, processor, and regulator. Each record takes the form \<Key>\<Data>\<Metadata>.
* Benchmark metrics are three-fold: correctness, completion time, and space overhead.

Generally, the paper emphasizes the phenomenon of metadata explosion due to which performance and scaling take a hit. This tradeoff is expected, as GDPR forces retrofitting of new features in ways that might not align with the original design principles.

# Open Questions and Future Work
## Obladi
1. Reliance on local centralized proxy introduces the issues of fault tolerance and scalability.
2. Complex SQL queries are not supported. The paper specifically mentions addressing the consistency challenge of maintaining oblivious indices in the presence of transactions.

## Differential Privacy
1. The privacy-utility framework could be made a bit more granular, as the original method of using global sensitivity is often too conservative for realistic datasets. For instance, the global sensitivity of querying for the median of some data is quite big such that the amount of noise added would also be big, affecting utility in a negative way.
2. Introducing differential privacy in the context of machine learning on a practical level has been an active area of research.

## GDPRbench
1. The code changes performed by the GDPRbench paper are not optimized. Optimizations to allow efficient auditing, efficient time-based deletion, and efficient metadata indexing would be helpful.