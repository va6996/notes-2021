---
title: "Storage: Privacy and Policies"
author: Neeraj Yadav <ny736@nyu.edu>
---
# Introduction

### GDPR Compliancy
As firms are getting more data-centric, they are collecting heaps of personal data from costumers. 
It is often observed that data is compromised by the firms to maximize their profits.
To prevent the abuse of personal data, the European Union enacted the General Data Protection Regulation (GDPR).
[Shastri et. al](https://arxiv.org/pdf/1910.00728.pdf) analyzes the legal rules and provides the characteristics of a GDPR compliant database system alongwith a benchmark
GDPRbench to assess the GDPR compliability. The authors also transform the Redis, PostgreSQL and a commercial database system to be GDPR compliant. 

### Differential Privacy
Aggregating the data can lead to information leak. [Dwork et al](https://cs.nyu.edu/~apanda/classes/sp21/papers/diffprivacy.pdf) surveys differential privacy which ensures that no individual information is leaked while joining the statistcal databases. 

### Obladi
The cloud based applications poses a threat of leaking sensitive information. Though the data can be encrypted but it is not suficient to hide access patterns. [Crooks et. al](https://cs.nyu.edu/~apanda/classes/sp21/papers/obladi.pdf) presents Obladi, a cloud-based transactional key-value store
that supports ACID transactions but hides from the cloud what, when, and how data is accessed. Obladi runs on top of ORAM (hides access patterns) and uses delayed visibility as an advantage to support ACID transactions.
 

# Motivation

### GDPR Compliancy
There were some instances where firms misused the personal data of customers and used it for other services than what they declared it to the customers. European Union countered this by establishing GDPR. GDPR provides EU consumers right to access, right to rectification, right to be forgotten, right to object and right to data portability. This is very significant as it gives more flexibility to customer (eg. deleting their data) but this also puts challenges before system designers to add extra features. For eg. Google was fined 50M euros for not obtaining customer consent in their ads personalization.  Hence, the database systems should be designed in such a way that it can efficiently accomodate the GDPR compliancy. There is a need of quantifiable metric to assess the GDPR compliancy because the companies prefer the minimal compliance that avoids legal troubles without incurring much performance overhead while customers would prefer a strict compliance. The regulators needs to resolve this controller-customer tussle and hence a quantifiable metric is necessary.

### Differential Privacy
Often it is required to report the aggregate data like census or aggregating the medical data of all the hospitals in a state. This however may lead to leak of individual data points. For example, if we report the average height of 'n' people and also the heights  h(-i)  of 'n-1' people leaving ith people out then this information reveals the individual heights of all the people. 

### Obladi
In recent few years, applications are largely shifted to cloud to utilise high computing resources at low prices and scalability. Applications may contain sensitive information like medical health records of people, banks financial data etc. Sharing the data to a third party poses security risks. It may be misused by a hacker or cloud provider. Encryption is a go-to approach to keep the data secure. However, the adversary can still get the information about the access patterns like 'what', 'when' and 'how' data is being accessed. For eg. if an oncologist is accessing the data then it reveals not only whether a patient has cancer but also the frequency of accesses reveal the type and severity of cancer. Therefore there is a need of obliviousness (hiding access patterns) to prevent the data abuse.

# Approaches

### GDPR Compliancy
GDPR rules mainly concentrate on following things:
1. **Principles of Data Processing**: limits usage of data to the purpose for which it is collected, well defined storage duration, protection against loss and destruction, customers consent 
2. **Rights of data subjects**: People have right to know the purpose, usage duration, accessibility to data etc.
3. **Responsibilities of data controllers and processors**: Contollers collect and utilize data and processors process data on behalf of controllers. For eg. Netflix (contoller) run their recommendation algorithm on Amazon's MapReduce (processor). Responsible for designing secure infrastructure, maintaining records of processing, controlling location of data etc.

GDPR compliancy is very challenging as the GDPR rules are intentionally vague in specification to handle technological advancements and GDPR's interpretation of personal data is very broad as it also includes the information which doesn't uniquely identify a person (for eg. search terms used over browser). 

GDPR metadata includes purpose, time to live, objections, audit trail, origin and sharing, automated decision making and associated person. The metadata explodes at a very fast rate. The large amount of metadata results in an increase in the storage space and latency as it needs to be updated after each access.

GDPR declares contollers and processors responsible for maintaining the privacy and protection of personal data. To do so, the following features should be incorporated in the database design:
1. **Timely Deletion**: Providing customer right to erase data at any time.
2. **Monitoring and Logging**: Monitoring the read/write operations.
3. **Indexing via Metadata**: Ability to access data based on metadata fields.
4. **Encryption**: Implemeting encryption over data in rest and transit.
5. **Access Time**: Limiting access to permitted entities for a well defined time.
![gdpr-im](https://github.com/neeraj71/BDML-/blob/main/gdpr-im.png)

The paper defines a new benchmark termed as GDPRBench to assess the GDPR compliance of database system. It provides a more robust assessment of GDPR compliancy. Currently, many cloud providers uses a yes/no format which makes it hard for regulators and customers to assess the GDPR compliancy. GDPRbench is composed of four core workloads:
1. **Controller**: Controller workload consists of operations like creation of records, timely deletion of records, updates to GDPR metadata towards managing access control, categorization, third-party sharing, and location management.
2. **Customer**: It represents the key rights that customers exercise while interfacing with the datastore like right to delete etc.
3. **Regulator**: It is to investigate and enforce the GDPR laws.
4. **Processor**: Works on behalf of contoller to do a well defined operation.

The workloads interface with data using operations termed as GDPR queries. GDPR queries are grouped into categories like create-record, delete-record-by, read-data-by, read-metadata-by, update-data-by, update-metadata-by and get-system.

GDPRbench captures three benchmark metrics for each workload:
1. **Correctness**: It is defined as the percentage of query responses that match the results expected by the benchmark.
2. **Completion Time**: It measures the time taken to complete all the GDPR queries.
3. **Space Overhead**: The ratio of total size of the database to the total size of personal data in it. 

Features like logging results in significant performance degradation. GDPR compliance results in poor scalability. Increasing the volume of personal data amounts, makes it challenging to comply with GDPR responsibilities in real-time. 

### Differential Privacy
* A query can be considered as a function that maps databases to real numbers (can be vector also). For eg, the query "CountP" counts the number of rows in the database having property P.
* If the database is X and the query function is f then the output is f(X). Now, differential privacy can be achieved by adding a suitable noise to the output. However if the noise is symmetric (eg spherical around origin) then adversary can know the noise distribution by asking the same question multiple times and hence it can cancel out the noise and get the information.  
* To achieve ε differential privacy, the mechanism adds independently generated noise with distribution Lap(Δf/ε) to each of the output terms. Here Δf is the sensitivity of f which is computed by taking the superior norm of difference between function f applied to the subsets of data D1 and D2. Note that D1 and D2 contains 'n-1' elements leaving one random element out.
* The above method works well, but in some use cases adding noise makes no sense. For eg. auctions where a slightly high price would prevent bidders from buying.
* A utility function u(X,y) measures the quality of output y given the database X.
* Exponential mechanism outputs y with probability proportional to  exp(−Δu(X, y)/2)  ensuring εΔu-differential privacy. Here Δu is the maximum possible change in the value of u due to change in the data of a single row.
* Exponential mechanism results in approximately-truthful auctions with nearly optimal selling price.

### Obladi
* Obladi consists of a centralized trusted component proxy that communicates with a fault-tolerant but untrusted entity, cloud storage. 
* Proxy handles concurrency control while the untrusted cloud storage stores the private data. 
* Obladi ensures that no information is leaked when a proxy makes a request to cloud storage.
* Obladi assumes that  cloud storage is reliable but  application clients and proxy may fail. Obladi hides access patterns and the durability and atomicity of transactions despite the mentioned failures.
* Proxy has two components: 
  * concurrency control unit
  * data manager comprised of a batch manager and an ORAM executor
* Goals of Proxy
  * guarantee good performance 
  * preserve correctness 
  * guarantee security 
*  Proxy partitions time into non-overlapping epochs. Epochs are the granularity at which Obladi guarantees durability and consistency
* Obladi guarantees that adversary would not have any information about:
  * the data accessed by ongoing transactions
  * the size of ongoing transactions
  * the type of operations in ongoing transactions
  * the outcome of ongoing transactions 
* ORAM hides access patterns for read and write. However ORAM :
  * Not Fault tolerant
  * Cannot support transcations
  * limited Concurrency control
* Obladi utilises the fact that transactions offer more flexibility than the single-value operations supported by ORAM i.e. ACID guarantees apply only when transactions commit and commit operations can be delayed.
* Obladi uses delayed visibility to partition transaction into fixed-sized epochs. It delays commit notifications until the epoch ends, buffering their execution at a trusted proxy and enforcing consistency and durability only at epoch boundaries.
* Delayed visibility boosts performance
  * Reduces number of requests sent to ORAM
  * Implement (MVCC) multi-versioned concurrency control algorithm on top of single-versioned ORAM 
* The performance gain by delayed visibility and optimistic concurrency control allows Obladi to execute OLTP workloads with reasonable throughput: within 5x to 12x of a non-oblivious baseline on the TPC-C, SmallBank, and Free Health applications. However, Latency overheads are higher (70× on TPC-C).





# Trade-Offs

### GDPR Compliancy
* The GDPR rules are vague in few scenarios and they can be carefully interpretated to reduce the cost and overhead of compliance. For eg. GDPR doesn't specify a strict time deadline about when a data deletion request is completed. Ideally, the deletion request should be completed in few seconds but in some cases it is delayed to reduce the overhead. Google cloud takes 180 days to process the deletion request. 

* There is a trade-off between the space overhead and completion time metric. We can reduce the space overhead by normalizing the metadata but this would increase the completion time of GDPR queries by requiring access to multiple tables.

### Differential Privacy
* Adding a large laplacian noise affects the utility of output as the output would be heavily deviated from actual value while an insignificant noise makes it easy for adversary to compromise the data.

### Obladi
* Obladi's perfromance is sensitive to epoch size. A very Large epoch size leads to idle time while a very small epoch size makes it difficult for transactions to finish.

*  **Concurrency control**: Pessimistic concurrency control like two-way locking which forces that write operation from transaction T1 can't execute concurrently with write operation to the same object from transaction T2 leads to information leakage even when ran over top of ORAM. Because a drop in throughput can reveal that the transaction is write heavy. Obladi uses an optimistic concurrency control which exposes uncommitted writes to ongoing transactions.



# Open Questions and Future Work

### GDPR Compliancy
The aim of authors while extending the code of the database systems was to just ensure that the systems are GDPR compliant. However, the code can be optimized to handle metadata  more efficiently by caching thus reducing perfromance overhead. Since now we have the features and benchmark, there is a need to reevaluate the design choices, optimization goals and devlope database systems from scratch with GDPR compliancy.

### Differential Privacy
Differential privacy is a wide area of research requiring analysis to add more complex noise which is harder to nullify by adversary and also achieve a good utlity value. 

### Obladi
Obladi does not support range or complex SQL queries. It uses a local centralized proxy which isn't highly scalable and prone to fault tolerance. Moreover, it may reveal the type of application if epoch size is too high. 
